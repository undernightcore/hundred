import { app, BrowserWindow, ipcMain } from "electron";
import { transcribeAudio } from "./services/whisper";
import { inferFromLLM } from "./services/ollama";
import {
  executeFunction,
  parseToolCall,
  prepareToolPrompt,
} from "./helpers/tools";
import { configDotenv } from "dotenv";

// This allows TypeScript to pick up the magic constants that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code (depending on
// whether you're running in development or production).
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;

configDotenv();

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require("electron-squirrel-startup")) {
  app.quit();
}

const createWindow = (): void => {
  // Create the browser window.
  const mainWindow = new BrowserWindow({
    height: 600,
    width: 800,
    webPreferences: {
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY,
    },
  });

  // and load the index.html of the app.
  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY);

  mainWindow.setMenu(null);
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on("ready", createWindow);

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on("window-all-closed", () => {
  app.quit();
});

app.on("activate", () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.

ipcMain.handle("prompt", async (_, audio: ArrayBuffer) => {
  console.clear();

  const transcription = await transcribeAudio(audio);
  console.log(transcription);

  const toolCall = await inferFromLLM(
    prepareToolPrompt(transcription),
    true,
    "mistral",
  ).then(parseToolCall);
  console.log(JSON.stringify(toolCall, null, 2));

  const tool = await executeFunction(toolCall.name, toolCall.arguments);
  const cookedResponse = tool(transcription);
  console.log(cookedResponse);

  const response = await inferFromLLM(cookedResponse, false, "llama3");
  console.log(response);

  return response
});
